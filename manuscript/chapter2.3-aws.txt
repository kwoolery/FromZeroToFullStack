## 2.3 Amazon Web Services (AWS)

AWS is an on-demand cloud computing platform from Amazon, offering dozens of services for serving and managing applications in a robust environment. With AWS, developers and systems engineers don't need to worry about the low-level details of hardware provision and deployment, since AWS provides an easy interface for bringing up new servers as-needed based on the immediate requirement of your application. In addition to the basic server management services, AWS provdides services for computing, storage, networking, database, analytics, application services, deployment, management, mobile, developer tools, and tools for the Internet of Things, as well as services to make machine learning accessible at scale. 

For this project, we'll be using AWS for media file storage, serving our API, as well as hosting our datastore. Most AWS services have a free-tier that allows developers to take the services for a test run without incurring any costs. I'll attempt to point out the thresholds that fall within this free-tier, and steer the project in a direction that won't require any initial investment when possible. As of the writing of this book, the following services are provided on the free tier with the given limitations. 

* Amazon Simple Storage Service (S3) - 5 GB Storage
* Amazon Elastic Compute Cloud (EC2) - 750 Hours of compute time per month on a t2.micro instance
* Amazon RDS - 750 Hours per month of a db.t2.micro database server
* Amazon DynamoDB - 25 GB Storage
* AWS Lambda - 1 Million free requests per month

### 2.3.1 Signing up for AWS

Navigate to the following url to signup for your free-tier AWS account: 
<https://portal.aws.amazon.com/billing/signup?redirect_url=https%3A%2F%2Faws.amazon.com%2Fregistration-confirmation#/start>

{width=50%,float=left}
![AWS Signup Page](images/chapter2.3-aws/aws-signup.jpg)

Enter your information, and follow the directions to the next page to enter your contact information. When choosing an account type, you should choose personal to begin with, then proceed to the billing page.

The billing page is going to ask you for your credit card information. Don't be alarmed, this information is only required if your usage exceeds the free tier limits as discussed above. You can look into advanced features of AWS that allow you to send alerts if usage is approaching the limits so you can make a decision to disable the service if necessary.

Once you input your billing information, you'll be asked to provide a phone number for verification. You'll get a call from AWS to verify a pin number presented to you on the sign up page. Just input the number, and you'll be successully verified and taken the the support plan page.

Choose the "Basic Plan" since we won't initially need support from Amazon, however, if you do need support in the future, you can choose to change plans to the one that works for your situation.

If everything goes well, you'll be presented with the following welcome page. From here, you can sign into the AWS Console where you'll manage all the services by clicking the "Sign In to the Console" button.

You'll be taken to the login page. Input the email you used during signup, then click 'Next' to be taken to the password page.

Finally, if the login succeeded, you'll be shown the AWS Console Dashboard page. You can choose to initialize, modify, and monitor all of the services provided by AWS. 

Congratulations, you've successfully signed up for Amazon Web Services!!! Everything you need to be successful is now at your fingertips. 

To being, We're going to be setting up the Simple Storage Service, or more commonly known as S3, for use in our application to store uploaded media from customers.  

### 2.3.2 Simple Storage Service (S3)

Amazon S3 is a massively scalable object storage system built to store and retrieve any amount of data from anywhere. It can be used as a simple key-value store, or as a full-blown filesystem where files can be accessed directly given a fully qualified path. It can even be setup to serve a static website with automatic index, and error pages, and redirects if necessary. We're not going to go into all of the features of S3 in this section, since there are an infinite number of options for storage, access, security, metadata, etc. If you're interested in knowing more about S3, I would recommend reading the Amazon S3 FAQ at https://aws.amazon.com/s3/faqs/?nc=sn&loc=6. 

In order to setup S3 for our use, we need to navigate to the S3 management console. From anywhere in the AWS Console, you can pull down the "Services" menu at the top left, and either choose S3 from the "Storage" second, or you can start typing S3 in the "Find a service by name or feature" input box. 

When you navigate to the S3 console for the first time, you'll see that you don't have any buckets. Buckets are globally unique containers for everything you store in Amazon S3. A globally unique container means that you must create a name for your bucket that nobody else has ever used. If you choose common words, AWS will probably complain that someone has used that name before. 

Here are two acceptible strategies for determining bucket names. The first, and simplest is to use your username as a prefix to the bucket name. In my case, my username is kevintruvu, so all of my buckets will have the name kevintruvu.<name of my bucket>. The likelyhood that someone has used this bucket name is much lower, since my username is unique to AWS as well. The second strategy should be used when you want to make the contents of the bucket available publicly by way of a unique hostname you have access to. This is helpful when hosting static websites from S3, but can be used for media delivery as well. An example would be if I wanted to have all the files in the bucket accessible from http://media.example.com/. In this case, I would name my bucket media.example.com, and setup a CNAME record for media.example.com to point to the appropriate S3 url (!!!FILL IN S3 URL!!!). 

Once, you've selected a naming strategy, click on the "+ Create bucket" button. You'll be taken to the following screen, where you can enter your DNS Compliant bucket name. I've decided to name my bucket kevintruvu.coffeeshopranker in order to guarantee uniqueness.

!!! IMAGE !!!

Click Next to configure the bucket options. You can leave the default options in place, and click Next to get to the permissions section. 

Since we're going to be using S3 to store, and deliver customer generated images, we'll need to allow end users to access the images directly. We'll give the public read access, and we'll use our application with our API key to upload images by way of the application. Go to the "Manage public permissions" settings, and choose the "Grant public access to this bucket" option. You'll be presented with a warning that this bucket will have public access, which is what we're trying to achieve. Click Next to move to the review section.

If everything looks as you expected, click on the "Create Bucket" button. 

If everyting was accepted, you'll be taken back to the S3 Console Dashboard where you'll se a list of available buckets. You should notice your newly created buck in the list, and the Access field should be marked as public. You can click on the bucket to enter the S3 Bucket Management Console. 

Since you haven't uploaded anything into the bucket yet, you'll be presented with an empty bucket. From here, you can create a new folder, or upload files, and folders directly. 

We don't have any files to upload yet, so let's create a folder. Click on the "+ Create folder" button. You'll be asked to name the folder, and whether you want to encrypt the contents. For our case, just name the folder "Test Folder" and click the Save button. 

You should now see your folder in the list of objects in the overview. Click on the folder to see the contents of the folder. From the listing page, you can either create another folder, or upload files. Click on the "Upload" button, and choose a file from your file system to upload by clicking the Add Files button. You can choose one or more files from your file system. You'll see the files that are ready to upload. Click Next to set the permissions of the file. 

On upload permissions section, you may notice that there's a "Manage public permissions" section similar to when you created the bucket. When uploading files from this interface, you have to choose permissions explicitly. There are ways to automate this when uploading from the command line, or from code, but for now in the manual upload form, you should choose "Grant public read access to this object" From the dropdown, and click Next to set the properties.

You can choose different storage options from the properties page, and whether the file will be encrypted, however, we're going to leave all the default properties for this file. If you want more information regaring the storage classes, refer to the S3 FAQ at  https://aws.amazon.com/s3/faqs/?nc=sn&loc=6. Click Next to get to the review page.

If everything looks good, click on the Upload button. Once the upload is successful, you should see the file listed in the directory. Clicking on the filename will take you to the overview page for that file. 

There are various actions that can be taken on the file such as downloading the file directly, or making the file public if it's not already. If you click open, you'll be able to see the contents of the file in your browser, even if the file is private. However, if the file is public, you'll be presented with a Link at the bottom of the page. You should see something similar to https://s3.amazonaws.com/kevintruvu.coffeeshopranker/testfolder/graph.jpg. It should become obvious now why the bucket name is so critical, all objects in S3 standard storage are accessible via the s3.amazonaws.com hostname, where the top level directory is your bucket name. 

If you were able to see the file in a browser, congratulations, you've successfully setup S3, and you now have the ability to upload and view media from a public url with only a few steps. 

We'll mostly be dealing with S3 in an automated fashion throughout the rest of the project, since we'll be uploading and viewing files from applications rather than directly from web pages, we'll be using the Go AWS SDK to accomplish this. We'll also touch on the AWS command line tools in order to list, and manage files in S3 in a similar way as would be done in the local file sytem. 

### 2.3.3 Elastic Compute Cloud (EC2)

Amazon EC2 is a scalable computing platform that provides virtual server instances for quickly scaling based on your application requirements. When launching an EC2 server, you can decide the type of machine, and the software that is preloaded by using an Amazon Machine Image (AMI). You can start with a fully loaded instance, or you can start with a barebones instance and add all the requirements yourself, and save your image as an AMI for quickly launching new instances with your requirements built in. If you need detailed information about all the features EC2 offers, you can read the EC2 documentation at <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html>. We'll mostly focus on setting up a single free-tiered instance to host our server-side application.

The first step is to navigate to the EC2 Dashboard by searching for the service name in the Services dropdown from anywhere in the AWS console. You should find yourself on the EC2 Dashboard. 

!!! Insert EC2 Dashboard Image !!!

Once on the EC2 Dashboard, click the Launch Instance button. You'll start the process of building your EC2 instance by first choosing which AMI to use. You can choose from a variety of available images, either for free, or you can navigate in the AWS Marketplace for exactly what you may be looking for. Keep in mind that the Marketplace images will typically charge based on compute time usage. For this project, we're going to go with one of the Quick Start images, and install what we need from scratch. 

!!! Insert Ubuntu Image Selection !!!

We want to make sure the image we choose is marked as Free Tier Eligible. For this project, you should use the Ubuntu Server 18.04 LTS (HVM), SSD Volume Type - ami-0ac019f4fcb7cb7e6 image. Click on the Select button to continue to Choose an Instance Type step.

!!! Insert Image of Instance Type Selector !!!

By default, the free tier t2.micro instance will be selected. If you want more information about the EC2 instance types, you can find details about the dozens of types at <https://aws.amazon.com/ec2/instance-types/>. The t2.micro is a single CPU virtual machine with 1GB of RAM. It's not a powerhouse, and wouldn't typically be suitable for a production application, however it's ideal for free prototyping, and it's free, which is a huge bonus. For this project, we're going to use the default configuraion settings, we do have to update the default security group though. You can get to the security group page by clicking on the Configure Security Group tab on the top progress bar. 

!!! Insert image of Security Group Tab !!!

Security groups on AWS are extremely flexible and allow you control port level access to your virtual servers. By default the SSH port 22 is open to all IP addresses. We'll leave that in place for now. 

!!! Insert Image of Review Page !!!

You'll notice a warning about limiting access to specific IP addresses from the review page. We're going to be accessing this server from mobile devices, and web browsers, so we need to make sure to allow all IP addresses. You'll see a warning about closing off access to all IP addresses. If you know your local IP address, it may make sense to limit SSH access, but for now, we'll leave this setting alone. Click on the Add Rule button.

!!! Insert image of Add Rule Row !!!

In order for our application to communicate with our server, we're going to need a port open to the public. Leave the type set to Custom TCP, change the Port Range value to 11373, and update the CIDR input to use 0.0.0.0/0. Use "Coffee Ranker App Comm Channel" for the description. Once you've setup the security rule, click on the blue Review and Launch button. 

On the Review Page, you'll once again be presented with the security warning about your server being open to the world. Once you've reviewed, launched, and accessed your server, you can choose to come back and update the security restrictions, but for this application, we're going to accept the risks, however, in a real world environment, you would absolutely want to limit access in order to avoid any security risks. 

!!! Insert review image !!!

The most important thing to review is to make sure the instance type you've selected is t2.micro. Anything else in the instance type will cost you based on compute type, so confirm that you have the free tier instance selected. If all the other information looks accurate in the Review page, go ahead and click the Launch button. You should get a dialog asking you to select or create a new key pair. 

!!! Insert Key Pair Image !!!

In order to provide an additional level of security, AWS requires a key pair to access the EC2 instances, at least initially. You can create a new key pair from this dialog. From the top dropdown, choose the "Create a key pair" option. This option will require you to name your key pair. For this key pair, set "Coffee Ranker Key Pair" as the name, then click on the Download Key Pair button. Store the downloaded pem file in a secure location, because you won't be able to download this file again. If you lose the file, you'll have to go about creating a new key pair, and updating the instance.

Once you have the key pair in a safe location, click on the Launch Instances button in the overlay. If everything went as expected, you should be taken to a Launch Status page. 

!!! Insert Launche Status Image !!!

You can check on the instance by clicking on the instance link in the box with the title "Your instances are now launching." Once you click on the button, you'll be taken to the instances listing page. This is where you will access all of your running instances. You should see your new server, and the current instance state. 

In order to connect to your newly launced server, you need to ssh into the machine by using the key pair file you downloaded earlier. If you select the instance, and click the Connect button, you'll be presented with detailed instructions on how to connect. 

!!! Image of Connect Instructions !!!

The following instructions for connecting are specific to Mac, and Linux, with a slight variation for Windows with Cygwin. If you're using something like PuTTY for Windows, you'll have to find the instuctions for connecting over SSH using a private key pair. 

The first step is to make sure the pem file you downloaded is in the correct location, and has the appropriate restricted permissions. You can do this by opening a terminal window, finding the pem file, and copying it to the .ssh directory in your home directory. Once the file is in the .ssh directory, run the following to change permissions. 

```
chmod 400 CoffeeRankerKeyPair.pem
```

This will give only your user access to read the file. You can now move up to your home directory, and access your server. Remember, your server hostname will be different than what is used in this example, just replace it with your hostname, and you should be able to access your server. You should also note the actual filename of the pem file. Run the following, or a variation based on your settings.

```
ssh -i ~/.ssh/CoffeeRankerKeyPair.pem ubuntu@ec2-54-165-222-48.compute-1.amazonaws.com
```

Since this is the first time you'll be accessing the server, you'll be presented with the following question. Type 'yes' to proceed. 

```
The authenticity of host 'ec2-54-165-222-48.compute-1.amazonaws.com (54.165.222.48)' can't be established.
ECDSA key fingerprint is SHA256:rP1PWuDqGRzSQeAoGHBmocJl1P+Ol526oJ+NGZ9wA6I.
Are you sure you want to continue connecting (yes/no)?
```

If you've setup everything correctly, you should get access to the command line prompt as the 'ubuntu' default user.  Congratulations, you've successfully setup your first EC2 server instance!

### 2.3.4 DynamoDB

### 2.3.5 Relational Database Service (RDS)

### 2.3.6 Lambda

